{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project\n",
    "### Predicting what loans will be defaulted\n",
    "\n",
    "Weâ€™ll use data from the lending club. Lending Club releases data for all of the approved and declined loan applications periodically on their website. You can select a few different year ranges to download the datasets (in CSV format) for both approved and declined loans.\n",
    "\n",
    "Before diving into the datasets themselves, let's get familiar with the data dictionary. The LoanStats sheet describes the approved loans datasets and the RejectStats describes the rejected loans datasets. Since rejected applications don't appear on the Lending Club marketplace and aren't available for investment, we'll be focusing on data on approved loans only.\n",
    "\n",
    "The approved loans datasets contain information on current loans, completed loans, and defaulted loans. Let's now define the problem statement for this machine learning project:\n",
    "Can we build a machine learning model that can accurately predict if a borrower will pay off their loan on time or not?\n",
    "Before we can start doing machine learning, we need to define what features we want to use and which column represents the target column we want to predict. Let's start by reading in the dataset and exploring it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Loans_2007.csv',low_memory=False)\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's clean the data by:\n",
    "removing the first line:\n",
    "- because it contains the extraneous text Notes offered by Prospectus (https://www.lendingclub.com/info/prospectus.action) instead of the column titles, which prevents the dataset from being parsed by the pandas library properly\n",
    "- removing all columns containing more than 50% missing values:\n",
    "which allows us to move faster since we can spend less time trying to fill these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42537, 52)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[1:]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_mark = len(df)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=1,thresh=half_mark).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42537, 52)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataframe contains many columns and can be cumbersome to try to explore all at once. Let's break up the columns into 3 groups of 18 columns and use the data dictionary to become familiar with what each column represents. As we understand each feature, we want to pay attention to any features that:\n",
    "\n",
    "- leak information from the future (after the loan has already been funded)\n",
    "- don't affect a borrower's ability to pay back a loan (e.g. a randomly generated ID value by Lending Club)\n",
    "- formatted poorly and need to be cleaned up\n",
    "- require more data or a lot of processing to turn into a useful feature\n",
    "- contain redundant information\n",
    "\n",
    "let's focus on just columns that we need to remove from consideration. Then, we can circle back and further dissect the columns we decided to keep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analyzing the first 18 columns, we can conclude that the following features need to be removed:\n",
    "\n",
    "- id: randomly generated field by Lending Club for unique identification purposes only\n",
    "- member_id: also a randomly generated field by Lending Club for unique identification purposes only\n",
    "- funded_amnt: leaks data from the future (after the loan is already started to be funded)\n",
    "- funded_amnt_inv: also leaks data from the future (after the loan is already started to be funded)\n",
    "- grade: contains redundant information as the interest rate column (int_rate)\n",
    "- sub_grade: also contains redundant information as the interest rate column (int_rate)\n",
    "- emp_title: requires other data and a lot of processing to potentially be useful\n",
    "- issue_d: leaks data from the future (after the loan is already completed funded)\n",
    "\n",
    "Let's now drop these columns from the Dataframe before moving onto the next group of columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"id\", \"member_id\", \"funded_amnt\", \"funded_amnt_inv\", \"grade\", \"sub_grade\", \"emp_title\", \"issue_d\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now drop:\n",
    "\n",
    "- total_pymnt: also leaks data from the future, (after the loan already started to be paid off)\n",
    "- total_pymnt_inv: also leaks data from the future, (after the loan already started to be paid off)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"zip_code\", \"out_prncp\", \"out_prncp_inv\", \"total_pymnt\", \"total_pymnt_inv\", \"total_rec_prncp\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last group of columns, we need to drop the following columns:\n",
    "\n",
    "- total_rec_int: leaks data from the future, (after the loan already started to be paid off),\n",
    "- total_rec_late_fee: also leaks data from the future, (after the loan already started to be paid off),\n",
    "- recoveries: also leaks data from the future, (after the loan already started to be paid off),\n",
    "- collection_recovery_fee: also leaks data from the future, (after the loan already started to be paid off),\n",
    "- last_pymnt_d: also leaks data from the future, (after the loan already started to be paid off),\n",
    "- last_pymnt_amnt: also leaks data from the future, (after the loan already started to be paid off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_amnt                                2500\n",
      "term                                60 months\n",
      "int_rate                               15.27%\n",
      "installment                             59.83\n",
      "emp_length                           < 1 year\n",
      "home_ownership                           RENT\n",
      "annual_inc                              30000\n",
      "verification_status           Source Verified\n",
      "loan_status                       Charged Off\n",
      "pymnt_plan                                  n\n",
      "purpose                                   car\n",
      "title                                    bike\n",
      "addr_state                                 GA\n",
      "dti                                         1\n",
      "delinq_2yrs                                 0\n",
      "earliest_cr_line                     Apr-1999\n",
      "inq_last_6mths                              5\n",
      "open_acc                                    3\n",
      "pub_rec                                     0\n",
      "revol_bal                                1687\n",
      "revol_util                               9.4%\n",
      "total_acc                                   4\n",
      "initial_list_status                         f\n",
      "last_credit_pull_d                   Sep-2013\n",
      "collections_12_mths_ex_med                  0\n",
      "policy_code                                 1\n",
      "application_type                   INDIVIDUAL\n",
      "acc_now_delinq                              0\n",
      "chargeoff_within_12_mths                    0\n",
      "delinq_amnt                                 0\n",
      "pub_rec_bankruptcies                        0\n",
      "tax_liens                                   0\n",
      "Name: 1, dtype: object\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "df = df.drop([\"total_rec_int\", \"total_rec_late_fee\", \"recoveries\", \"collection_recovery_fee\", \"last_pymnt_d\", \"last_pymnt_amnt\"], axis=1)\n",
    "print(df.iloc[0])\n",
    "print(df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by becoming familiar with the columns in the dataset, we were able to reduce the number of columns from 52 to 32 columns. We now need to decide on a target column that we want to use for modeling.\n",
    "\n",
    "We should use the loan_status column, since it's the only column that directly describes if a loan was paid off on time, had delayed payments, or was defaulted on the borrower. Currently, this column contains text values and we need to convert it to a numerical one for training a model. Let's explore the different values in this column and come up with a strategy for converting the values in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fully Paid                                             33135\n",
       "Charged Off                                             5634\n",
       "Does not meet the credit policy. Status:Fully Paid      1988\n",
       "Current                                                  961\n",
       "Does not meet the credit policy. Status:Charged Off      761\n",
       "Late (31-120 days)                                        24\n",
       "In Grace Period                                           20\n",
       "Late (16-30 days)                                          8\n",
       "Default                                                    3\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8 different possible values for the loan_status column. You can read about most of the different loan statuses on the [Lending Clube webste](https://help.lendingclub.com/hc/en-us)\n",
    "\n",
    "After reading and researching the possible status, we only need the Fully Paid and the Charged off status. These two represent the loans that were paid off on time and the ones that weren't. \n",
    "\n",
    "Let's drop all the rows that do not have either of these status\n",
    "\n",
    "Since we're interested in being able to predict which of these 2 values a loan will fall under, we can treat the problem as a binary classification one. Let's remove all the loans that don't contain either Fully Paid and Charged Off as the loan's status and then transform the Fully Paid values to 1 for the positive case and the Charged Off values to 0 for the negative case. While there are a few different ways to transform all of the values in a column, we'll use the Dataframe method replace. According to the documentation, we can pass the replace method a nested mapping dictionary\n",
    "\n",
    "Lastly, one thing we need to keep in mind is the class imbalance between the positive and negative cases. While there are 33,136 loans that have been fully paid off, there are only 5,634 that were charged off. This class imbalance is a common problem in binary classification and during training, the model ends up having a strong bias towards predicting the class with more observations in the training set and will rarely predict the class with less observations. The stronger the imbalance, the more biased the model becomes. There are a few different ways to tackle this class imbalance, which we'll explore later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['loan_status']=='Fully Paid')|(df['loan_status']=='Charged Off')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38769, 32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(to_replace={\n",
    "    'loan_status':{\n",
    "        'Fully Paid':1,\n",
    "        'Charged Off':0\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To wrap up this mission, let's look for any columns that contain only one unique value and remove them. These columns won't be useful for the model since they don't add any information to each loan application. In addition, removing these columns will reduce the number of columns we'll need to explore furthe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pymnt_plan', 'initial_list_status', 'collections_12_mths_ex_med', 'policy_code', 'application_type', 'acc_now_delinq', 'chargeoff_within_12_mths', 'delinq_amnt', 'tax_liens']\n"
     ]
    }
   ],
   "source": [
    "orig_columns = df.columns\n",
    "drop_columns = []\n",
    "for col in orig_columns:\n",
    "    col_series = df[col].dropna().unique()\n",
    "    if len(col_series) == 1:\n",
    "        drop_columns.append(col)\n",
    "df = df.drop(drop_columns, axis=1)\n",
    "print(drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38769, 23)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "We've been abe to clean the dataset down to 23 useful columns. Good data cleaning!!! \n",
    "Let's now export the df to a csv file so we can continue our project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_loans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
